{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unit 5 - Building the model layers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Eda_5xwlmjT"
      },
      "source": [
        "# Tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFdi8Q52lTXu"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zoof5cm8lktk"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbqOG4mppTG5",
        "outputId": "8b088457-0c61-47be-bf7d-af23291e0e3e"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dSZQ2GgpkM6"
      },
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        # super(NeuralNetwork, self).__init__()  # Initializes internal Module state. (Python 2 & 3)\n",
        "        super().__init__()  # Python 3 only\n",
        "        self.flatten = nn.Flatten()  # change Size([batch, dim1, dim2, ..., dimN]) into Size([batch, dim1 * dim2 * ... * dimN])\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP4zjhi4yEn5",
        "outputId": "d81cf239-608b-406a-bfa8-89ad37391d19"
      },
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI_n825XyPNd",
        "outputId": "a826b86f-9bc4-4e2c-a562-56c1c79475df"
      },
      "source": [
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(dim=1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted class: tensor([2], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KeRhyrd0Ep1",
        "outputId": "847bb2e1-12cf-4a04-abd6-078c2c1536a4"
      },
      "source": [
        "input_image = torch.rand(3, 28, 28)\n",
        "print(input_image.size())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9-6vySb0iq2",
        "outputId": "bb97d35b-347d-4170-efd0-6d600dad54ea"
      },
      "source": [
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu9rtPJAgPfj",
        "outputId": "366d6fb5-1820-4df9-924f-e3727097b905"
      },
      "source": [
        "layer1 = nn.Linear(in_features=28 * 28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3Hf3A4ggiwr",
        "outputId": "69033ebe-c959-4828-dd81-21912115ef45"
      },
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before ReLU: tensor([[-0.0240, -0.0129, -0.3088,  0.3150,  0.3681, -0.5604, -0.1308,  0.3970,\n",
            "          0.1100, -0.0405,  0.5774,  0.2673, -0.3496,  0.3433,  0.3891, -0.0158,\n",
            "          0.8871, -0.2001,  0.0502,  0.5852],\n",
            "        [ 0.3855,  0.1676, -0.1491,  0.5962,  0.1382, -0.1839, -0.1654,  0.6320,\n",
            "         -0.0593,  0.0346,  0.4010,  0.0664,  0.0635,  0.4181,  0.7895,  0.3732,\n",
            "          0.3736, -0.0037, -0.2997,  0.2187],\n",
            "        [ 0.3433,  0.2812, -0.3080,  0.6776,  0.0482, -0.3910, -0.4639,  0.3982,\n",
            "         -0.0720, -0.1216,  0.2265,  0.0913,  0.0840,  0.5901,  0.2960, -0.1085,\n",
            "          0.6149, -0.1477,  0.2292,  0.0775]], grad_fn=<AddmmBackward>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.0000, 0.0000, 0.0000, 0.3150, 0.3681, 0.0000, 0.0000, 0.3970, 0.1100,\n",
            "         0.0000, 0.5774, 0.2673, 0.0000, 0.3433, 0.3891, 0.0000, 0.8871, 0.0000,\n",
            "         0.0502, 0.5852],\n",
            "        [0.3855, 0.1676, 0.0000, 0.5962, 0.1382, 0.0000, 0.0000, 0.6320, 0.0000,\n",
            "         0.0346, 0.4010, 0.0664, 0.0635, 0.4181, 0.7895, 0.3732, 0.3736, 0.0000,\n",
            "         0.0000, 0.2187],\n",
            "        [0.3433, 0.2812, 0.0000, 0.6776, 0.0482, 0.0000, 0.0000, 0.3982, 0.0000,\n",
            "         0.0000, 0.2265, 0.0913, 0.0840, 0.5901, 0.2960, 0.0000, 0.6149, 0.0000,\n",
            "         0.2292, 0.0775]], grad_fn=<ReluBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hugZ_tFQhRYS",
        "outputId": "2d6c1b58-7d8e-4b6a-8628-370caa1b56af"
      },
      "source": [
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3, 28, 28)\n",
        "logits = seq_modules(input_image)\n",
        "print(logits)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.1119,  0.1697,  0.1613,  0.4375,  0.2416,  0.1671,  0.2358, -0.4817,\n",
            "         -0.0501,  0.3790],\n",
            "        [ 0.0450,  0.3229,  0.0495,  0.2361,  0.3127,  0.1710,  0.2387, -0.3779,\n",
            "          0.0183,  0.2382],\n",
            "        [ 0.0588,  0.1516,  0.1192,  0.3696,  0.1063,  0.1670,  0.2743, -0.3776,\n",
            "         -0.0660,  0.3014]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM3SzfOfi1Sy",
        "outputId": "c1b8c000-315e-4cad-b5bf-fa317a98d099"
      },
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)\n",
        "print(pred_probab)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0950, 0.1006, 0.0998, 0.1315, 0.1081, 0.1003, 0.1075, 0.0524, 0.0808,\n",
            "         0.1240],\n",
            "        [0.0906, 0.1197, 0.0911, 0.1097, 0.1185, 0.1028, 0.1100, 0.0594, 0.0883,\n",
            "         0.1100],\n",
            "        [0.0932, 0.1023, 0.0990, 0.1272, 0.0977, 0.1038, 0.1156, 0.0602, 0.0823,\n",
            "         0.1188]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMT01Hq3jWVa",
        "outputId": "7b9e22c6-a50d-4734-ee3c-ce51c4296a3b"
      },
      "source": [
        "print(\"Model structure: \", model, \"\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values: {param[:2]} \\n\")  # only print part of the params"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model structure:  NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ") \n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values: tensor([[ 0.0122,  0.0301, -0.0039,  ..., -0.0023,  0.0072, -0.0278],\n",
            "        [-0.0194, -0.0269, -0.0121,  ..., -0.0054,  0.0177, -0.0053]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values: tensor([ 0.0355, -0.0102], device='cuda:0', grad_fn=<SliceBackward>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values: tensor([[ 2.1920e-02, -2.0422e-02,  1.9535e-05,  ...,  2.5925e-02,\n",
            "         -4.0062e-02, -1.9650e-02],\n",
            "        [-3.9202e-02, -3.1425e-02, -3.8142e-02,  ...,  3.1520e-04,\n",
            "         -3.6802e-02, -8.9158e-03]], device='cuda:0', grad_fn=<SliceBackward>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values: tensor([-0.0058, -0.0351], device='cuda:0', grad_fn=<SliceBackward>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values: tensor([[-0.0093, -0.0087, -0.0364,  ..., -0.0346,  0.0276,  0.0110],\n",
            "        [-0.0042,  0.0065, -0.0082,  ...,  0.0415,  0.0427,  0.0342]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values: tensor([ 0.0334, -0.0165], device='cuda:0', grad_fn=<SliceBackward>) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}